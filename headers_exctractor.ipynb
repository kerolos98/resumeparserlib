{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kerolos98/resumeparserlib/blob/main/headers_exctractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRCk0g6nGs2L",
        "outputId": "d53a2d99-fdef-45e0-8e79-ee0c0cacb168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.21.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.21.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.8/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.8/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf\n",
        "!pip install transformers\n",
        "!pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYIePNJPYe_a",
        "outputId": "81accc37-9fc8-4044-8c1e-c2dc5a2861c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en_core_web_lg==2.3.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz (782.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from en_core_web_lg==2.3.1) (2.3.9)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.21.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.8)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.25.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.7.9)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.6)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.10)\n",
            "Building wheels for collected packages: en_core_web_lg\n",
            "  Building wheel for en_core_web_lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en_core_web_lg: filename=en_core_web_lg-2.3.1-py3-none-any.whl size=782936122 sha256=6f9a09768724e96dacb24e33a43b97c040723c24c9355ec70df2d41eecd0605d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/bb/bb/bdc918f4b37d930a1be9ed876e7b2c2ee518a34803d78a248e\n",
            "Successfully built en_core_web_lg\n",
            "Installing collected packages: en_core_web_lg\n",
            "  Attempting uninstall: en_core_web_lg\n",
            "    Found existing installation: en-core-web-lg 3.4.1\n",
            "    Uninstalling en-core-web-lg-3.4.1:\n",
            "      Successfully uninstalled en-core-web-lg-3.4.1\n",
            "Successfully installed en_core_web_lg-2.3.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75vZAQHn-vlY"
      },
      "source": [
        "# **outputs of the same pdf**\n",
        "\n",
        "\n",
        "*   /content/drive/MyDrive/مجلد بلا عنوان/Resume/3341114f-ff74-4ccc-82be-61adf99598b3bhanu_sai-converted.pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "\n",
        "def convert_to(folder, source, timeout=None):\n",
        "    args = [libreoffice_exec(), '--headless', '--convert-to', '.pdf', '--outdir', folder, source]\n",
        "\n",
        "    process = subprocess.run(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=timeout)\n",
        "    filename = re.search('-> (.*?) using filter', process.stdout.decode())\n",
        "\n",
        "    return filename.group(1)\n",
        "\n",
        "\n",
        "def libreoffice_exec():\n",
        "    # TODO: Provide support for more platforms\n",
        "    if sys.platform == 'darwin':\n",
        "        return '/Applications/LibreOffice.app/Contents/MacOS/soffice'\n",
        "    return 'libreoffice'"
      ],
      "metadata": {
        "id": "dU7rXXgC2Tn7"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "J2eUVzVl5LIj"
      },
      "outputs": [],
      "source": [
        "\n",
        "import fitz\n",
        "import spacy \n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "def scrape(filePath):\n",
        "    results = [] # list of tuples that store the information as (text, font size, font name)\n",
        "    size = []\n",
        "    fonts=[]\n",
        "    combination=[]\n",
        "    pdf = fitz.open(filePath) # filePath is a string that contains the path to the pdf\n",
        "    for page in pdf:\n",
        "        dict = page.get_text(\"dict\")\n",
        "        blocks = dict[\"blocks\"]\n",
        "        for block in blocks:\n",
        "            if \"lines\" in block.keys():\n",
        "                spans = block['lines']\n",
        "                for span in spans:\n",
        "                    data = span['spans']\n",
        "                    for lines in data:\n",
        "                      if len(lines['text'])>=2: \n",
        "                            results.append([lines['text'], lines['size'], lines['font']])\n",
        "                            size.append(lines['size'])\n",
        "                            fonts.append(lines['font'])\n",
        "                            combination.append((lines['size'], lines['font']))\n",
        "\n",
        "                            # lines['text'] -> string, lines['size'] -> font size, lines['font'] -> font name\n",
        "    pdf.close()\n",
        "    return results ,size,fonts,combination\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "tf_DAJbY8YLz"
      },
      "outputs": [],
      "source": [
        "data,size,fonts,combination=scrape('/content/drive/MyDrive/kerolos emad__ (3)-1.pdf')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "u_XmDMie-wQF"
      },
      "outputs": [],
      "source": [
        "def bold_data(data):\n",
        "    data_bold=[]\n",
        "    for d in data:\n",
        "      if 'Bold' in d[2] or d[0].isupper() :\n",
        "        if d[0]!=' ':\n",
        "          data_bold.append(d)\n",
        "    return data_bold      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "TqGAviUHhgsB"
      },
      "outputs": [],
      "source": [
        "def bold_filter(data):\n",
        "  keywords=['summary','work experience','phone number','contact','email','address','education','Languages','projects','skills','ACHIEVEMENTS','Details','Links','Hobbies']\n",
        "  new=[]\n",
        "  for d in data:\n",
        "    for key in keywords:\n",
        "      search = nlp(d[0].lower())\n",
        "      main = nlp(key)\n",
        "      if main.similarity(search)>0.5:\n",
        "        if d in new:\n",
        "          continue\n",
        "        new.append(d)\n",
        "  return new "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkJgoTYti1Qw",
        "outputId": "019ca962-c7bb-4b41-9016-a165ed8efa96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-134-19fe8a2c0477>:8: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  if main.similarity(search)>0.5:\n"
          ]
        }
      ],
      "source": [
        "headers=bold_filter(bold_data(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MCJ-X_GOPB2",
        "outputId": "96341e28-1ea2-4df1-8f36-75f2786adda8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['LINKEDIN:', 9.0, 'CenturyGothic'],\n",
              " ['EMAIL:', 9.0, 'CenturyGothic'],\n",
              " ['EDUCATION', 11.0, 'CenturyGothic-Bold'],\n",
              " ['Graduation Project:', 9.0, 'CenturyGothic-Bold'],\n",
              " ['Coursework:', 9.0, 'CenturyGothic-Bold'],\n",
              " ['WORK EXPERIENCE', 11.0, 'CenturyGothic-Bold'],\n",
              " ['Predictive Analytics Modeler Training – IBM', 9.0, 'CenturyGothic-Bold'],\n",
              " ['Projects:', 9.0, 'CenturyGothic-Bold'],\n",
              " ['FEEDBACKS', 7.699999809265137, 'CenturyGothic'],\n",
              " ['REVIEW MODEL', 7.699999809265137, 'CenturyGothic'],\n",
              " [' SKILLS', 11.0, 'CenturyGothic-Bold']]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "headers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "exzHCTdFxjh7"
      },
      "outputs": [],
      "source": [
        "from numpy import True_\n",
        "import re\n",
        "def data_organizer(data,headers):\n",
        "    dict_data=dict()\n",
        "    for i in range(len(headers)):\n",
        "      try:\n",
        "          dict_data[headers[i][0]]=data[data.index(headers[i])+1:data.index(headers[i+1])]\n",
        "      except IndexError:  \n",
        "          dict_data[headers[i][0]]=data[data.index(headers[i])+1:-1]\n",
        "    return dict_data\n",
        "def size_structures(data,state):\n",
        "    temp=0\n",
        "    memory=''\n",
        "    tree=dict()\n",
        "    for d in data:\n",
        "        sentence = re.sub(r\"\\s+\", \"\", d[0], flags=re.UNICODE)\n",
        "        if sentence!='':\n",
        "            if d[1]>=temp:\n",
        "              if state==True:\n",
        "                if 'Bold' in d[2]:\n",
        "                  memory=d[0]\n",
        "                  temp=d[1]\n",
        "                  tree[d[0]]=[]\n",
        "                  \n",
        "              else:  \n",
        "                  memory=d[0]\n",
        "                  temp=d[1]\n",
        "                  tree[d[0]]=[]\n",
        "            else:\n",
        "              tree[memory].append(d[0]) \n",
        "    return tree\n",
        "def bold_state(data):\n",
        "  state=False\n",
        "  for d in data :\n",
        "    if 'Bold' in d[2]:\n",
        "      state=True\n",
        "      break\n",
        "  return state       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "2d1fMvZk0D7r"
      },
      "outputs": [],
      "source": [
        "dict_data=data_organizer(data,headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V6jz_NSNRof",
        "outputId": "d6906989-f117-4646-f06e-940233630235"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['LINKEDIN:', 'EMAIL:', 'EDUCATION', 'Graduation Project:', 'Coursework:', 'WORK EXPERIENCE', 'Predictive Analytics Modeler Training – IBM', 'Projects:', 'FEEDBACKS', 'REVIEW MODEL', ' SKILLS'])"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "dict_data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_data['EDUCATION']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdnBWamjHUqC",
        "outputId": "69f97285-0596-45d2-9694-02d172e8699e"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['BSc in Computer Science - Higher Technological Institute (HTI) 10',\n",
              "  9.0,\n",
              "  'CenturyGothic-Bold'],\n",
              " ['th', 5.399999618530273, 'CenturyGothic-Bold'],\n",
              " ['of', 9.0, 'CenturyGothic-Bold'],\n",
              " ['Ramadan City', 9.0, 'CenturyGothic-Bold'],\n",
              " ['Attended: 2016 - 2020', 9.0, 'CenturyGothic'],\n",
              " ['GPA: 3.2, Graduated(HTI-CS-2020)', 9.0, 'CenturyGothic']]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "n52Ls-Dn0jOT"
      },
      "outputs": [],
      "source": [
        "#section content size seperation\n",
        "def size_seperator(dict_data):\n",
        "  for k,v in dict_data.items():\n",
        "      dict_data[k]=size_structures(v,bold_state(v))\n",
        "  return  dict_data   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_data=size_seperator(dict_data)"
      ],
      "metadata": {
        "id": "cnpIQxi619wV"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_data['EMAIL:']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odn8HfWEHhDM",
        "outputId": "7c42d6b3-0acb-4fa9-97e8-07e26f6db311"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kemad57@gmail.com': []}"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "zJg4IC8hzG0d"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def date_period(input_string):\n",
        "      # a generator will be returned by the datefinder module. I'm typecasting it to a list. Please read the note of caution provided at the bottom.\n",
        "      matches = list(datefinder.find_dates(input_string))\n",
        "\n",
        "      if len(matches) > 0:\n",
        "          # date returned will be a datetime.datetime object. here we are only using the first match.\n",
        "          return matches\n",
        "      else:\n",
        "          return ('No dates found')\n",
        "def discription(ents,text):\n",
        "  for k,v in ents.items():\n",
        "      text=text.replace(v,' ')\n",
        "  return text\n",
        "def entities(text):\n",
        "    doc = nlp(text)\n",
        "    counter=0\n",
        "    entities=dict()\n",
        "    for entity in doc.ents:\n",
        "      entities[entity.label_+str(counter)]= entity.text\n",
        "      counter+=1\n",
        "    return   entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "LmFTW7_DZnbU"
      },
      "outputs": [],
      "source": [
        "def dic_check(dict0):\n",
        "  state=False\n",
        "  for k,v in dict0.items():\n",
        "    if len(v)>0:\n",
        "      state=True\n",
        "      break\n",
        "  return  state   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _correct(text):\n",
        "        \n",
        "      gfg = TextBlob(text)\n",
        "      \n",
        "      # using TextBlob.correct() method\n",
        "      gfg = gfg.correct()\n",
        "      return str(gfg)"
      ],
      "metadata": {
        "id": "1G8pgp705rfT"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "bLJL6CtK_WEj"
      },
      "outputs": [],
      "source": [
        "def structured_entities_based(dict_data):\n",
        "    title=[]\n",
        "    dates=[]\n",
        "    jsons=dict()\n",
        "    for k,v in dict_data.items():\n",
        "          loader=dict()\n",
        "          state=dic_check(v)\n",
        "          if state==True:\n",
        "            \n",
        "            for c,d in v.items():\n",
        "              obj_data=dict()\n",
        "              text=''.join(d)\n",
        "              ents1=entities(c)\n",
        "              ents2=entities(text)\n",
        "              discriptions='no data'\n",
        "              if  bool(ents2) :\n",
        "                  discriptions=_correct(discription(ents2,str(text)))\n",
        "              obj_data['title']=c\n",
        "              obj_data['full_text']=text\n",
        "              obj_data['entities']=[ents1,ents2]\n",
        "              obj_data['discription']=discriptions\n",
        "              loader[c]=obj_data\n",
        "              \n",
        "            jsons[k]=loader\n",
        "            \n",
        "          else:\n",
        "            obj_data=dict()\n",
        "            text=''.join(v.keys())\n",
        "            ents=entities(text)\n",
        "            discriptions='no data'\n",
        "            if  bool(ents) :\n",
        "                  discriptions=_correct(discription(ents,str(text)))\n",
        "            obj_data['full_text']=text\n",
        "            obj_data['entities']=ents\n",
        "            obj_data['discription']=discriptions\n",
        "            jsons[k]=obj_data\n",
        "    return  jsons      \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVdwCxJpFIQV",
        "outputId": "3cddb142-bae2-4721-aff0-fdf793f97b92"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Phone ': {'full_text': ':  +91 7207999519',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'Notice Period : Immediate Joiner': {'full_text': '',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'Email   :  akbarbasha5943@gmail.com': {'full_text': '',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'Professional Summary:': {'full_text': '3.4 Years of IT experience in  ',\n",
              "  'entities': {'DATE0': '3.4 Years'},\n",
              "  'discription': '  of of experience in  '},\n",
              " 'Manual Testing  ': {'full_text': ' API Testing  POSTMAN ',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'understanding': {'full_text': ' the ',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'Requirements': {'full_text': ' and ',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'analysis': {'full_text': ' the ', 'entities': {}, 'discription': 'no data'},\n",
              " 'testing scope': {'full_text': 'items',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'Tracking': {'full_text': ' the ', 'entities': {}, 'discription': 'no data'},\n",
              " 'changes of Requirements': {'full_text': 'Test ScenariosTest CasesTest Case DesignTest Case Execution Preparing  Test Data ',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'Finding ': {'full_text': ' BugsLoggingBugsTrackingBugs till closureTest processeffective Test CasesSDLC STLC Team player',\n",
              "  'entities': {'ORG0': 'STLC Team'},\n",
              "  'discription': ' BugsLoggingBugsTrackingBugs till closureTest processeffective West CasesSDLC   player'},\n",
              " ' Web Application testing': {'full_text': 'Smoke Testing',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'Functional Testing': {'full_text': 'GUI Testing',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'Integration Testing': {'full_text': 'Re-Testing',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'Regression Testing': {'full_text': '',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'Sanity Testing': {'full_text': '', 'entities': {}, 'discription': 'no data'},\n",
              " 'Compatibility Testing ': {'full_text': 'End to End Testing  System TestingREST  APIPOSTMANGET POSTPUT PATCHDELETE SOAPSOAP UIJIRAAzure DevOpsAgile methodologySprint PlanningSprint grooming Scrum MeetingSprint ReviewSprint Retrospective',\n",
              "  'entities': {'PRODUCT0': 'Scrum MeetingSprint ReviewSprint Retrospective'},\n",
              "  'discription': 'And to And Resting  System TestingREST  APIPOSTMANGET POSTPUT PATCHDELETE SOAPSOAP UIJIRAAzure DevOpsAgile methodologySprint PlanningSprint grooving  '},\n",
              " 'Work Experience:': {'full_text': 'Worked as a Software Engineer in IBM since Aug 2018 to Till Date.',\n",
              "  'entities': {'ORG0': 'IBM', 'DATE1': 'Aug 2018'},\n",
              "  'discription': 'Worked as a Software Engineer in   since   to Will Late.'},\n",
              " 'Education Details:': {'full_text': 'B. Tech from BITS, Adoni affiliated to JNTU Anantapur,  A.P.Diploma from TGLG Ploytechnic, Adoni affiliated to SBTET, Kurnool, A.P.SSC from Sri Saradaniketan High School, Adoni, Kurnool, A.P.',\n",
              "  'entities': {'ORG0': 'B. Tech',\n",
              "   'ORG1': 'BITS',\n",
              "   'PERSON2': 'Adoni',\n",
              "   'PERSON3': 'JNTU Anantapur',\n",
              "   'ORG4': 'TGLG Ploytechnic',\n",
              "   'PERSON5': 'Adoni',\n",
              "   'PERSON6': 'Kurnool',\n",
              "   'PERSON7': 'A.P.SSC',\n",
              "   'ORG8': 'Sri Saradaniketan High School',\n",
              "   'PERSON9': 'Adoni',\n",
              "   'GPE10': 'Kurnool',\n",
              "   'ORG11': 'A.P.'},\n",
              "  'discription': '  from  ,   affiliated to  ,   Diploma from  ,   affiliated to SBTET,  ,   from  ,  ,  ,  '},\n",
              " 'Software Skills:': {'full_text': 'SQLJIRAAzure DevOpsPOSTMANSOAPUI',\n",
              "  'entities': {'ORG0': 'SQLJIRAAzure'},\n",
              "  'discription': '  DevOpsPOSTMANSOAPUI'},\n",
              " 'Achievements:': {'full_text': 'Best Performance Award ',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'Projects Summary:': {'full_text': '',\n",
              "  'entities': {},\n",
              "  'discription': 'no data'},\n",
              " 'Project ': {' 2  :  ': {'title': ' 2  :  ',\n",
              "   'full_text': 'Project Title: One Config (OC)Client: HPDuration: Jan 2020 to till dateDomain: E-Commerce (B2B)Bug Management Tool: Azure DevOps.Test SuiteAzure DevOps.Team Size: 11 membersRole: Test Engineer',\n",
              "   'entities': [{'CARDINAL0': '2'},\n",
              "    {'CARDINAL0': 'One',\n",
              "     'DATE1': 'Jan 2020',\n",
              "     'ORG2': 'E-Commerce',\n",
              "     'ORG3': 'B2B)Bug Management Tool:',\n",
              "     'CARDINAL4': '11'}],\n",
              "   'discription': 'Project Title:   Konig (of)Client: HPDuration:   to till dateDomain:   (  Azure DevOps.West SuiteAzure DevOps.Team Size:   membersRole: West Engineer'}},\n",
              " 'Description:': {'HP Store': {'title': 'HP Store',\n",
              "   'full_text': '',\n",
              "   'entities': [{'ORG0': 'HP Store'}, {}],\n",
              "   'discription': 'no data'},\n",
              "  'B2C (Business to Customer)': {'title': 'B2C (Business to Customer)',\n",
              "   'full_text': '',\n",
              "   'entities': [{}, {}],\n",
              "   'discription': 'no data'},\n",
              "  'Roles and Responsibilities: ': {'title': 'Roles and Responsibilities: ',\n",
              "   'full_text': 'Following Agile Scrum methodology Participated in Sprint Planning and Sprint Grooming sessionsGetting the requirements from Azure DevOps (ADO) tool assigned by lead Understanding the requirements and getting clarifications from lead/scrum masterDeveloping Test Scenarios, Test cases and Test Data based on requirementsSending the test cases for peer and lead reviews and updating the test cases basedupon the review comments Executing the test cases and logging the bugs in ADO tool if there is any deviationbetween expected and actual resultAttending the daily Scrum meetings Performing Smoke test after every build Providing the sign off for the stories for which testing is completed and doesn’t haveany open bugsIdentifying the Regression Test Cases and Sanity Test Cases at the end of the sprint ',\n",
              "   'entities': [{},\n",
              "    {'ORG0': 'Sprint Planning',\n",
              "     'ORG1': 'ADO',\n",
              "     'ORG2': 'Test Data',\n",
              "     'ORG3': 'ADO',\n",
              "     'WORK_OF_ART4': 'Scrum meetings Performing Smoke',\n",
              "     'LAW5': 'the Regression Test Cases and Sanity Test Cases'}],\n",
              "   'discription': 'Following Agile Serum methodology Participated in   and Print Drooping sessionsGetting the requirements from Azure DevOps ( ) tool assigned by lead Understanding the requirements and getting clarification from lead/serum masterDeveloping West Scenario, West cases and   based on requirementsSending the test cases for peer and lead reviews and dating the test cases basedupon the review comments Executing the test cases and logging the bags in   tool if there is any deviationbetween expected and actual resultAttending the daily   test after every build Providing the sign off for the stories for which testing is completed and doesn’t haven open bugsIdentifying   at the end of the spring '}},\n",
              " 'Roles and Responsibilities: ': {'Agile Scrum': {'title': 'Agile Scrum',\n",
              "   'full_text': '',\n",
              "   'entities': [{}, {}],\n",
              "   'discription': 'no data'},\n",
              "  'Sprint Planning': {'title': 'Sprint Planning',\n",
              "   'full_text': '',\n",
              "   'entities': [{'ORG0': 'Sprint Planning'}, {}],\n",
              "   'discription': 'no data'},\n",
              "  'Sprint Grooming': {'title': 'Sprint Grooming',\n",
              "   'full_text': '',\n",
              "   'entities': [{}, {}],\n",
              "   'discription': 'no data'},\n",
              "  'Azure DevOps (ADO)': {'title': 'Azure DevOps (ADO)',\n",
              "   'full_text': '',\n",
              "   'entities': [{'ORG0': 'ADO'}, {}],\n",
              "   'discription': 'no data'},\n",
              "  'Test Scenarios': {'title': 'Test Scenarios',\n",
              "   'full_text': '',\n",
              "   'entities': [{}, {}],\n",
              "   'discription': 'no data'},\n",
              "  'Test cases': {'title': 'Test cases',\n",
              "   'full_text': '',\n",
              "   'entities': [{}, {}],\n",
              "   'discription': 'no data'},\n",
              "  'Test Data': {'title': 'Test Data',\n",
              "   'full_text': '',\n",
              "   'entities': [{}, {}],\n",
              "   'discription': 'no data'},\n",
              "  'peer': {'title': 'peer',\n",
              "   'full_text': '',\n",
              "   'entities': [{}, {}],\n",
              "   'discription': 'no data'},\n",
              "  'lead reviews': {'title': 'lead reviews',\n",
              "   'full_text': '',\n",
              "   'entities': [{}, {}],\n",
              "   'discription': 'no data'},\n",
              "  'Scrum meetings ': {'title': 'Scrum meetings ',\n",
              "   'full_text': '',\n",
              "   'entities': [{}, {}],\n",
              "   'discription': 'no data'},\n",
              "  'Project ': {'title': 'Project ',\n",
              "   'full_text': '',\n",
              "   'entities': [{}, {}],\n",
              "   'discription': 'no data'},\n",
              "  ' 1  :  ': {'title': ' 1  :  ',\n",
              "   'full_text': 'Project Title: ETR (e-Commerce Transformation) – B2CClient: HPDuration: Aug 2018 to Dec 2019Project Management Tool: JIRA and TestRailTeam Size: 9 membersRole : Test Associate',\n",
              "   'entities': [{'CARDINAL0': '1'},\n",
              "    {'ORG0': 'ETR', 'DATE1': 'Aug 2018', 'NORP2': 'JIRA', 'CARDINAL3': '9'}],\n",
              "   'discription': 'Project Title:   (e-Commerce Transformation) – B2CClient: HPDuration:   to Dec 201 Project Management Fool:   and TestRailTeam Size:   membersRole : West Associate'}}}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def file_extraction(path):\n",
        "  try:\n",
        "    data,size,fonts,combination=scrape(path)\n",
        "  except:\n",
        "    result=convert_to('TEMP Directory',  path, timeout=30)\n",
        "    data,size,fonts,combination=scrape(result)\n",
        "  headers=bold_filter(bold_data(data))\n",
        "  dict_data=  data_organizer(data,headers)\n",
        "  #json file based on text featrures\n",
        "  json_text=dict_data\n",
        "  with open(\"json_text.json\",\"w\") as f:\n",
        "    json.dump(json_text,f)\n",
        "  # json files with more structure based on size and font style \n",
        "  dict_data=size_seperator(dict_data)\n",
        "  json_size_font=dict_data\n",
        "  with open(\"json_size_font.json\",\"w\") as f:\n",
        "    json.dump(json_size_font,f)\n",
        "  #json file based on extracting section entities and descriptions\n",
        "  dict_data= structured_entities_based(dict_data)\n",
        "  with open(\"entities_data.json\",\"w\") as f:\n",
        "    json.dump(dict_data,f)\n"
      ],
      "metadata": {
        "id": "YYPBhm_25bVK"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_extraction('/content/drive/MyDrive/Stockholm-Resume-Template-Simple (2).pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGl6l3pl937s",
        "outputId": "5fff89fc-49e0-4d9a-926f-e5efe714f02b"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-134-19fe8a2c0477>:8: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  if main.similarity(search)>0.5:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "LcdGHobrW57O"
      },
      "outputs": [],
      "source": [
        "!pip freeze > requirements.txt "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZeYJ0JGtEFAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xRYsNYODP-YgC05XGod1K2x5H5HxKewB",
      "authorship_tag": "ABX9TyOGA1ebfhDcyQwmM5PWdD9R",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}